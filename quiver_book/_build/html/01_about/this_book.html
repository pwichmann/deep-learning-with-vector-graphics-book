
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>This book &#8212; Deep Learning with Vector Graphics</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="The author" href="the_author.html" />
    <link rel="prev" title="Deep Learning with Vector Graphics" href="../index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/q_logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep Learning with Vector Graphics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Deep Learning with Vector Graphics
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   This book
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="the_author.html">
   The author
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Background knowledge
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02_background/vector_graphics.html">
   Vector Graphics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_background/vector_graphics/svg.html">
     Scalable Vector Graphics (SVG) format
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02_background/deep_learning.html">
   Deep Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_background/deep_learning/rnn.html">
     RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_background/deep_learning/lstm.html">
     LSTM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_background/deep_learning/mdn.html">
     Mixture Density Networks (MDN)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_background/deep_learning/transformer.html">
     Transformer
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02_background/DL_with_vector_graphics.html">
   Deep Learning with Vector Graphics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_background/DL_with_vector_graphics/arguing_for_e2e_approach.html">
     Arguing for E-2-E approach
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02_background/DL_with_vector_graphics/challenges_of_vector_graphics.html">
     Challenges of Vector Graphics
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Relevant work
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03_related_work/academic_papers.html">
   Key academic publications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/papers/Graves_2014.html">
     Alex Graves (2014) | Generating Sequences With Recurrent Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/papers/Ha_2015_handwriting.html">
     David Ha (Dec 2015) | Handwriting Generation Demo in TensorFlow (blog post)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/papers/Ha_2015_kanji.html">
     David Ha (Dec 2015) | Recurrent Net Dreams Up Fake Chinese Characters in Vector Format with TensorFlow (blog post)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/papers/Carter_et_al_2016.html">
     Carter et al. (2016) | Four Experiments in Handwriting with a Neural Network (Distill publication)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/papers/Ha_Eck_2017.html">
     Ha &amp; Eck (2017) | A Neural Representation of Sketch Drawings (sketch-rnn)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/papers/Zhong_2018.html">
     Kimberli Zhong (2018) | Learning to Draw Vector Graphics: Applying Generative Modeling to Font Glyphs (Master thesis @ MIT)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/papers/Lopes_et_al_2019.html">
     Lopes et al. (2019) | A Learned Representation for Scalable Vector Graphics (svg-vae)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/papers/Carlier_et_al_2020.html">
     Carlier et al. (2020) | DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/papers/Li_et_al_2020.html">
     Li et al. (2020) | Differentiable Vector Graphics Rasterization for Editing and Learning (diffvg)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/papers/Reddy_et_al_2021.html">
     Reddy et al. (2021) | Im2Vec: Synthesizing Vector Graphics without Vector Supervision
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03_related_work/further_academic_papers.html">
   Further academic publications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/further_academic_papers/campbell_and_kautz_2014.html">
     Campbell and Kautz (2014) | Learning a Manifold of Fonts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/further_academic_papers/Das_2020.html">
     Das et al. (2020) | BézierSketch: A generative model for scalable vector sketches
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/further_academic_papers/zhao_et_al_2020.html">
     Zhao et al. (2020) | ICONATE: Automatic Compound Icon Generation and Ideation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/further_academic_papers/Das_2021.html">
     Das et al. (2021) | Cloud2Curve: Generation and Vectorization of Parametric Sketches
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/further_academic_papers/yang_2021_sketchaa.html">
     Yang et al. (2021) | SketchAA: Abstract Representation for Abstract Sketches
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/further_academic_papers/wang_and_lian_2021.html">
     Wang and Lian (2021) | DeepVecFont: Synthesizing High-quality Vector Fonts via Dual-modality Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/further_academic_papers/Jiang_2021.html">
     Jiang et al. (2021) | Recognizing Vector Graphics without Rasterization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03_related_work/other_relevant_work.html">
   Other relevant work
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/other_relevant_work/greydanus_2016.html">
     Sam Greydanus (2016) | Scribe: Generating Realistic Handwriting with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/other_relevant_work/google_quickdraw_2017.html">
     Google’s “Quick, Draw!” (2017)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/other_relevant_work/vectoglyph_2019.html">
     Nicolas Boillot’s Vectoglyph (2019)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03_related_work/other_relevant_work/gan_xml_fixer_2019.html">
     GAN XML Fixer (2019)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03_related_work/datasets.html">
   Datasets
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Data representation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../04_data_representation/from_strokes_to_svg.html">
   From strokes to SVG
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04_data_representation/common_preprocessing.html">
   Common SVG preprocessing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_data_representation/preprocessing/first_steps.html">
     First steps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_data_representation/preprocessing/deminifying_path_data.html">
     “De-minifying” path data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_data_representation/preprocessing/harmonizing_positioning.html">
     Harmonizing command positioning logic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_data_representation/preprocessing/decomposition_of_basic_shapes.html">
     Decomposition of basic SVG shapes to paths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_data_representation/preprocessing/reducing_path_commands.html">
     Reducing the set of different path commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_data_representation/preprocessing/normalization.html">
     Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_data_representation/preprocessing/path_simplification.html">
     Path simplification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_data_representation/preprocessing/finishing_touches.html">
     Finishing touches
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04_data_representation/preprocessing/embedding.html">
     Embedding
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Acknowledgements
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../99_acknowledgements/acknowledgements.html">
   Acknowledgements
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/01_about/this_book.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F01_about/this_book.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#raster-images-vs-vector-graphics">
   Raster images vs. vector graphics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-is-deep-learning-with-vector-graphics-special">
   Why is Deep Learning with Vector Graphics special?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#so-how-do-we-deal-with-vector-graphics">
   So, how do we deal with vector graphics?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#we-could-avoid-svg-altogether-and-only-work-with-raster-images">
     We could avoid SVG altogether and only work with raster images
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#we-could-just-treat-the-svg-as-text">
     We could just treat the SVG as text
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#we-could-encode-the-svg-definition">
     We could encode the SVG definition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#we-could-use-a-multi-modal-model">
     We could use a multi-modal model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#we-could-include-the-rasterizer-in-the-model">
     We could include the rasterizer in the model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#we-could-also-include-a-text-description-in-the-model">
     We could also include a text description in the model
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="this-book">
<h1>This book<a class="headerlink" href="#this-book" title="Permalink to this headline">¶</a></h1>
<p>This book aims to introduce the domain of applying Deep Learning to <a class="reference external" href="https://en.wikipedia.org/wiki/Vector_graphics">vector graphics</a>, such as <a class="reference external" href="https://developer.mozilla.org/en-US/docs/Web/SVG">SVG</a>, and to identify and summarise relevant prior work.</p>
<p>The focus is on content related to the aim of end-to-end generative deep learning models for vector graphics. But other content, such as object localization and classification within vector graphics, may also be covered.</p>
<p>This book is an hommage to those amazingly talented and kind scientists, engineers and artists who paved the way and inspired the author, such as <strong>David Ha</strong> (<a class="reference external" href="https://twitter.com/hardmaru">Twitter</a>, <a class="reference external" href="https://otoro.net/ml/">Website</a>) or <strong>Raphael Gontijo Lopes</strong> (<a class="reference external" href="https://twitter.com/iraphas13">Twitter</a>, <a class="reference external" href="https://raphagl.com/">Website</a>).</p>
<div class="section" id="raster-images-vs-vector-graphics">
<h2>Raster images vs. vector graphics<a class="headerlink" href="#raster-images-vs-vector-graphics" title="Permalink to this headline">¶</a></h2>
<p>Raster images consist of a grid of pixels. The application of Deep Learning to raster images has been well-researched and is relatively straightforward.</p>
<p>Vector graphics, on the other hand, are not based on a grid of pixels but based on mathematical descriptions of points, lines etc. in an x,y (Cartesian) coordinate system. A common vector graphics format is the Scalable Vector Graphics format (SVG). One major advantage of vector graphics is that they are infinitely scalable. Another advantage is that their file size is small and independent of the image’s size and resolution. This is why, for instance, fonts, icons and logos are often designed as vector graphics.</p>
</div>
<div class="section" id="why-is-deep-learning-with-vector-graphics-special">
<h2>Why is Deep Learning with Vector Graphics special?<a class="headerlink" href="#why-is-deep-learning-with-vector-graphics-special" title="Permalink to this headline">¶</a></h2>
<p>Deep Learning requires the input data to be represented as a collection of numeric values (also called a <em>tensor</em>). This book was also half-jokingly dubbed “<em>Scalable Tensor Graphics</em>” at some point for that reason – which sounds like an extension from vectors to multidimensional tensors.</p>
<p>Representing a raster image as such a tensor is easy: In a simple black-and-white image, a single pixel already holds a single numeric value, e.g. from 0 (black) to 255 (white), with all the shades of grey in between. So, the units of an artificial neural network can (more or less) directly be fed with these values.</p>
<p>Vector graphics are different. One standard format for vector graphics is the Scalable Vector Graphics format - or short: SVG. This format is XML-based and, thus, a text-based description of the image using a hierarchical structure of nested tags and their associated attributes.</p>
<p>Below is an example of simple SVG:</p>
<div class="highlight-XML notranslate"><div class="highlight"><pre><span></span><span class="nt">&lt;svg</span> <span class="na">version=</span><span class="s">&quot;1.1&quot;</span>
     <span class="na">width=</span><span class="s">&quot;200&quot;</span> <span class="na">height=</span><span class="s">&quot;200&quot;</span>
     <span class="na">xmlns=</span><span class="s">&quot;http://www.w3.org/2000/svg&quot;</span><span class="nt">&gt;</span>

  <span class="nt">&lt;rect</span> <span class="na">width=</span><span class="s">&quot;100%&quot;</span> <span class="na">height=</span><span class="s">&quot;100%&quot;</span> <span class="na">fill=</span><span class="s">&quot;blue&quot;</span> <span class="nt">/&gt;</span>

  <span class="nt">&lt;circle</span> <span class="na">cx=</span><span class="s">&quot;100&quot;</span> <span class="na">cy=</span><span class="s">&quot;100&quot;</span> <span class="na">r=</span><span class="s">&quot;80&quot;</span> <span class="na">fill=</span><span class="s">&quot;yellow&quot;</span> <span class="nt">/&gt;</span>

  <span class="nt">&lt;text</span> <span class="na">x=</span><span class="s">&quot;100&quot;</span> <span class="na">y=</span><span class="s">&quot;125&quot;</span> <span class="na">font-size=</span><span class="s">&quot;60&quot;</span> <span class="na">text-anchor=</span><span class="s">&quot;middle&quot;</span> <span class="na">fill=</span><span class="s">&quot;black&quot;</span><span class="nt">&gt;</span>SVG<span class="nt">&lt;/text&gt;</span>

  <span class="nt">&lt;path</span> <span class="na">d=</span><span class="s">&quot;M 30 160 q 50 -50 140 0&quot;</span> <span class="na">stroke=</span><span class="s">&quot;red&quot;</span> <span class="na">stroke-width=</span><span class="s">&quot;8&quot;</span> <span class="na">fill=</span><span class="s">&quot;none&quot;</span> <span class="nt">/&gt;</span>

<span class="nt">&lt;/svg&gt;</span>
</pre></div>
</div>
<p>Once rendered by the browser, this looks like this:</p>
<div class="figure align-default" id="about-example-svg">
<a class="reference internal image-reference" href="../_images/example.svg"><img alt="Example SVG paper" src="../_images/example.svg" width="200px" /></a>
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">Example SVG as rendered by the browser</span><a class="headerlink" href="#about-example-svg" title="Permalink to this image">¶</a></p>
</div>
<p>The properties of vector graphics pose a number of challenges when it comes to Deep Learning (see the separate chapter on the topic).</p>
</div>
<div class="section" id="so-how-do-we-deal-with-vector-graphics">
<h2>So, how do we deal with vector graphics?<a class="headerlink" href="#so-how-do-we-deal-with-vector-graphics" title="Permalink to this headline">¶</a></h2>
<p>So how do we deal with vector graphics for problems like classification or for creating new vector graphics using generative models?</p>
<div class="section" id="we-could-avoid-svg-altogether-and-only-work-with-raster-images">
<h3>We could avoid SVG altogether and only work with raster images<a class="headerlink" href="#we-could-avoid-svg-altogether-and-only-work-with-raster-images" title="Permalink to this headline">¶</a></h3>
<p>We could just render the SVG to a raster image file, such as a PNG file. Once input files have been converted, we would only work with raster images.</p>
<p>But then our deep neural network will never learn anything about vector graphics and their specific definition. Unless trained otherwise, it will never be able to output a vector graphic. Existing tools that can convert raster images into vector graphics (so-called tracers or vectorizers) do not perform well, e.g. in the case of color gradients.</p>
</div>
<div class="section" id="we-could-just-treat-the-svg-as-text">
<h3>We could just treat the SVG as text<a class="headerlink" href="#we-could-just-treat-the-svg-as-text" title="Permalink to this headline">¶</a></h3>
<p>We could just treat the SVG just like any text sequence in Deep Learning. Text sequences get split into tokens, such as individual characters or individual words. And then each token gets converted into a vector. A few years ago, this would have been one-hot vectors. Nowadays, these are generally embeddings.</p>
<p>If we do this, we can apply Recurrent Neural Networks (RNNs), a class of neural networks that is able to learn sequences of inputs. Given a beginning of an SVG, we could be able to predict the next missing part. And then given that, we could again (auto-regressively) predict the next missing part – and so on. Such a model would surely learn something about the syntax of SVGs. But will it develop an understanding of the resulting visuals? Is a sequence of text characters really the appropriate data representation?</p>
</div>
<div class="section" id="we-could-encode-the-svg-definition">
<h3>We could encode the SVG definition<a class="headerlink" href="#we-could-encode-the-svg-definition" title="Permalink to this headline">¶</a></h3>
<p>We could our domain knowledge of the SVG standard to encode the definition of each SVG of the training dataset into a numerical vector.</p>
<p>This is not trivial. An SVG is an XML document of (often deeply) nested tags. And each tag can have a multitude of attributes that impact the way the SVG looks when rendered on the screen.</p>
<p>Because only a few attributes are used in any given tag, the resulting vector will be sparse, that is it will contain many zero values.</p>
<p>Converting an SVG into a vector requires a complex, hard-coded logic. Changes to the SVG standard would require the logic to be updated.</p>
<p>Another concern is that a model trained on this data may still not “understand” the impact of changes in the SVG definition on the resulting rendered image.</p>
</div>
<div class="section" id="we-could-use-a-multi-modal-model">
<h3>We could use a multi-modal model<a class="headerlink" href="#we-could-use-a-multi-modal-model" title="Permalink to this headline">¶</a></h3>
<p>We could feed in both the SVG and the corresponding PNG as inputs to the model. By using this multi-modality (i.e. two different sensory inputs of the same “object”), we may be able to improve the model’s “understanding” how SVG definition and PNG render relate to each other.</p>
<p>But how would the model know how to adjust the SVG to better match the desired visual?</p>
</div>
<div class="section" id="we-could-include-the-rasterizer-in-the-model">
<h3>We could include the rasterizer in the model<a class="headerlink" href="#we-could-include-the-rasterizer-in-the-model" title="Permalink to this headline">¶</a></h3>
<p>A rasterizer renders the SVG definition into a pixel-based graphic that can be displayed on a screen. Only recently a rasterizer was developed that is differentiable. That means any loss in the raster space could be propagated back to required changes in the SVG definition.</p>
</div>
<div class="section" id="we-could-also-include-a-text-description-in-the-model">
<h3>We could also include a text description in the model<a class="headerlink" href="#we-could-also-include-a-text-description-in-the-model" title="Permalink to this headline">¶</a></h3>
<p>Multi-modal models using images and a text description, like DALL-E or imagen, allow users to generate an image by simply providing a text prompt. If we could obtain text descriptions for the SVG images, this could allow users of the trained model to generate SVG images simply by providing a descriptive text prompt.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./01_about"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="../index.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Deep Learning with Vector Graphics</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="the_author.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">The author</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Pascal Wichmann<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>