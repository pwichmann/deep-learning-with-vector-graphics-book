
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Arguing for E-2-E approach &#8212; Deep Learning with Vector Graphics</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Challenges of Vector Graphics" href="challenges_of_vector_graphics.html" />
    <link rel="prev" title="Deep Learning with Vector Graphics" href="../DL_with_vector_graphics.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/q_logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep Learning with Vector Graphics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../index.html">
   Deep Learning with Vector Graphics
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../01_about/this_book.html">
   This book
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../01_about/the_author.html">
   The author
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Background knowledge
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../vector_graphics.html">
   Vector Graphics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../vector_graphics/svg.html">
     Scalable Vector Graphics (SVG) format
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../deep_learning.html">
   Deep Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_learning/rnn.html">
     RNN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_learning/lstm.html">
     LSTM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_learning/mdn.html">
     Mixture Density Networks (MDN)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../DL_with_vector_graphics.html">
   Deep Learning with Vector Graphics
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Arguing for E-2-E approach
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="challenges_of_vector_graphics.html">
     Challenges of Vector Graphics
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Relevant work
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../03_related_work/academic_papers.html">
   Key academic publications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/papers/Graves_2014.html">
     Alex Graves (2014) | Generating Sequences With Recurrent Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/papers/Ha_2015_handwriting.html">
     David Ha (Dec 2015) | Handwriting Generation Demo in TensorFlow (blog post)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/papers/Ha_2015_kanji.html">
     David Ha (Dec 2015) | Recurrent Net Dreams Up Fake Chinese Characters in Vector Format with TensorFlow (blog post)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/papers/Carter_et_al_2016.html">
     Carter et al. (2016) | Four Experiments in Handwriting with a Neural Network (Distill publication)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/papers/Ha_Eck_2017.html">
     Ha &amp; Eck (2017) | A Neural Representation of Sketch Drawings (sketch-rnn)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/papers/Zhong_2018.html">
     Kimberli Zhong (2018) | Learning to Draw Vector Graphics: Applying Generative Modeling to Font Glyphs (Master thesis @ MIT)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/papers/Lopes_et_al_2019.html">
     Lopes et al. (2019) | A Learned Representation for Scalable Vector Graphics (svg-vae)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/papers/Carlier_et_al_2020.html">
     Carlier et al. (2020) | DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/papers/Li_et_al_2020.html">
     Li et al. (2020) | Differentiable Vector Graphics Rasterization for Editing and Learning (diffvg)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/papers/Reddy_et_al_2021.html">
     Reddy et al. (2021) | Im2Vec: Synthesizing Vector Graphics without Vector Supervision
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../03_related_work/further_academic_papers.html">
   Further academic publications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/further_academic_papers/campbell_and_kautz_2014.html">
     Campbell and Kautz (2014) | Learning a Manifold of Fonts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/further_academic_papers/Das_2020.html">
     Das et al. (2020) | BézierSketch: A generative model for scalable vector sketches
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/further_academic_papers/Das_2021.html">
     Das et al. (2021) | Cloud2Curve: Generation and Vectorization of Parametric Sketches
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/further_academic_papers/yang_2021_sketchaa.html">
     Yang et al. (2021) | SketchAA: Abstract Representation for Abstract Sketches
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/further_academic_papers/wang_and_lian_2021.html">
     Wang and Lian (2021) | DeepVecFont: Synthesizing High-quality Vector Fonts via Dual-modality Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/further_academic_papers/Jiang_2021.html">
     Jiang et al. (2021) | Recognizing Vector Graphics without Rasterization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../03_related_work/other_relevant_work.html">
   Other relevant work
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/other_relevant_work/greydanus_2016.html">
     Sam Greydanus (2016) | Scribe: Generating Realistic Handwriting with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/other_relevant_work/google_quickdraw_2017.html">
     Google’s “Quick, Draw!” (2017)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/other_relevant_work/vectoglyph_2019.html">
     Nicolas Boillot’s Vectoglyph (2019)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../03_related_work/other_relevant_work/gan_xml_fixer_2019.html">
     GAN XML Fixer (2019)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../03_related_work/datasets.html">
   Datasets
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Data representation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../04_data_representation/from_strokes_to_svg.html">
   From strokes to SVG
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../04_data_representation/common_preprocessing.html">
   Common SVG preprocessing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04_data_representation/preprocessing/first_steps.html">
     First steps
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04_data_representation/preprocessing/deminifying_path_data.html">
     “De-minifying” path data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04_data_representation/preprocessing/harmonizing_positioning.html">
     Harmonizing command positioning logic
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04_data_representation/preprocessing/decomposition_of_basic_shapes.html">
     Decomposition of basic SVG shapes to paths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04_data_representation/preprocessing/reducing_path_commands.html">
     Reducing the set of different path commands
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04_data_representation/preprocessing/normalization.html">
     Normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04_data_representation/preprocessing/path_simplification.html">
     Path simplification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04_data_representation/preprocessing/finishing_touches.html">
     Finishing touches
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../04_data_representation/preprocessing/embedding.html">
     Embedding
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Acknowledgements
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../99_acknowledgements/acknowledgements.html">
   Acknowledgements
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/02_background/DL_with_vector_graphics/arguing_for_e2e_approach.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F02_background/DL_with_vector_graphics/arguing_for_e2e_approach.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-efficient-and-faster">
   1. More efficient and faster
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-effective">
   2. More effective
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rasterising-a-vector-graphics-leads-to-information-loss">
     2.1 Rasterising a vector graphics leads to information loss
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maintaining-symmetries-perfect-angles-clear-color-boundaries-etc">
     2.2 Maintaining symmetries, perfect angles, clear color boundaries etc.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#current-vectorizers-are-doing-a-poor-job">
     2.3 Current vectorizers are doing a poor job
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#examples">
     Examples
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusion-regarding-poor-vectorizers">
     Conclusion regarding poor vectorizers
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="arguing-for-e-2-e-approach">
<h1>Arguing for E-2-E approach<a class="headerlink" href="#arguing-for-e-2-e-approach" title="Permalink to this headline">¶</a></h1>
<p>A book about Deep Learning with Vector Graphics also needs to make the point why an end-to-end (E-2-E) approach appears to be a desirable objective.</p>
<p>End-to-end in a Machine Learning context refers to a single model that is able to consume the available input and covers all the steps required to produce the desired output. End-to-end in this context shall refer to a generative Deep Learning model that is fed vector graphics and can directly output vector graphics. If vector graphics are the desired output but the model only generates raster images that still need to be vectorized, then this would not be called end-to-end.</p>
<p>End-to-end in this context shall not exclude multi-modal approaches where, <em>in addition</em> to the vector graphic, other types of inputs are used, such as text descriptions or the corresponding raster image. Multi-modal may even be a required setting for some problems.</p>
<p>Here are a few bold claims (that may still require evidence):</p>
<div class="section" id="more-efficient-and-faster">
<h2>1. More efficient and faster<a class="headerlink" href="#more-efficient-and-faster" title="Permalink to this headline">¶</a></h2>
<p>Training on SVG could be much faster since vector graphics can store information much more efficiently than raster images. This is obviously the case if an image has been designed as a vector graphic from the start. The rastered image file will be much larger and even “empty” pixels need to be described using their RGB(A) values.</p>
<p>Compare a simple 10x10 rectangle in a 16x16 image as vector graphic against its rasterized version.</p>
<div class="figure align-default" id="simple-rect-raster">
<a class="reference internal image-reference" href="../../_images/simple_rect_raster.png"><img alt="simple_rect_raster" src="../../_images/simple_rect_raster.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-number">Fig. 4 </span><span class="caption-text">Simple 10x10 rectangle in a 16x16 image; illustration of how a raster image would store the information using RGB pixel values</span><a class="headerlink" href="#simple-rect-raster" title="Permalink to this image">¶</a></p>
</div>
<p>Even at the low resolution of 16x16 pixels, so much more information needs to be processed than in the equivalent vector graphic. 256 pixels in the image times the 3 values for each RGB channel.</p>
<p>In comparison, the SVG code of the rectangle (decomposed to a path) would look like this:</p>
<div class="highlight-XML notranslate"><div class="highlight"><pre><span></span><span class="nt">&lt;svg</span> <span class="na">width=</span><span class="s">&quot;16&quot;</span> <span class="na">height=</span><span class="s">&quot;16&quot;</span><span class="nt">&gt;</span>
    <span class="nt">&lt;path</span> 
      <span class="na">d=</span><span class="s">&quot;</span>
<span class="s">        M 3, 3</span>
<span class="s">        L 13, 3</span>
<span class="s">        L 13, 13</span>
<span class="s">        L 3, 13</span>
<span class="s">        z</span>
<span class="s">        &quot;</span> <span class="nt">/&gt;</span>
<span class="nt">&lt;/svg&gt;</span>
</pre></div>
</div>
<p>And this is also how a vector graphics editor would show the rectangle – as a closed path of just for connected points.</p>
<div class="figure align-default" id="simple-rect-inkscape">
<a class="reference internal image-reference" href="../../_images/simple_rect_inkscape.png"><img alt="simple_rect_inkscape" src="../../_images/simple_rect_inkscape.png" style="width: 600px;" /></a>
<p class="caption"><span class="caption-number">Fig. 5 </span><span class="caption-text">Simple 10x10 rectangle in a 16x16 image; screenshot of how the vector graphics editor Inkscape shows the SVG</span><a class="headerlink" href="#simple-rect-inkscape" title="Permalink to this image">¶</a></p>
</div>
<p>Training DeepSVG, for example, on a small dataset using an RTX 3090 takes less than an hour. Training models for raster images generally takes much longer: days, if not weeks.</p>
</div>
<div class="section" id="more-effective">
<h2>2. More effective<a class="headerlink" href="#more-effective" title="Permalink to this headline">¶</a></h2>
<p>If obtaining SVG is our goal, then the approach of using generative models for raster images and to then convert their output to vector graphics is futile. Current generative models are not conditioned to produce output that is easily converted to vector graphics, especially when it comes to colour images (as opposed to black and white images). And such a conditioning would not be trivial.</p>
<div class="section" id="rasterising-a-vector-graphics-leads-to-information-loss">
<h3>2.1 Rasterising a vector graphics leads to information loss<a class="headerlink" href="#rasterising-a-vector-graphics-leads-to-information-loss" title="Permalink to this headline">¶</a></h3>
<p>Unlike raster images, vector graphics contain additional structural information (e.g. how shapes are represented, how low-level elements are grouped together to form high-level shapes, …).</p>
<p>Learning about the composition of an SVG is only possible if this information is fed into the model. A rasterised image has lost that information.</p>
</div>
<div class="section" id="maintaining-symmetries-perfect-angles-clear-color-boundaries-etc">
<h3>2.2 Maintaining symmetries, perfect angles, clear color boundaries etc.<a class="headerlink" href="#maintaining-symmetries-perfect-angles-clear-color-boundaries-etc" title="Permalink to this headline">¶</a></h3>
<p>Many logos and icons make use of perfect symmetries and perfect 90° angles. This information could be maintained if both input and output are vector graphics. Colour inputs to a generative model for raster images often lead to watercolor effects where boundaries between shapes get blurry.</p>
<p><strong>Example:</strong></p>
<p>Have a look at the following figure which shows 4 different icons which have been reconstructed by a VAE. The icons were originally SVG icons and presented to the VAE as 128x128 rasterised images. Thus, the VAE was trained on raster images only.</p>
<div class="figure align-default" id="reconstructed-icons-vae">
<a class="reference internal image-reference" href="../../_images/reconstructed_icons_vae.png"><img alt="Reconstructed icons using a VAE" src="../../_images/reconstructed_icons_vae.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 6 </span><span class="caption-text">Unclear color boundaries (VAE-reconstructed icons; VAE was trained on 128x128 pixel rasterised vector graphics)</span><a class="headerlink" href="#reconstructed-icons-vae" title="Permalink to this image">¶</a></p>
</div>
<p>While the black and white characters would be relatively easy to vectorize, the icon in the upper right corner would not. The outline of the overall shape and the check mark have been reconstructed very well. But the blue shapes that make up the shield bleed into each other and now have irregular color gradients.</p>
<p>In the following figure, the target icon in the lower right corner looks like a watercolor painting. Especially this watercolor effect makes vectorizing these results very difficult.</p>
<div class="figure align-default" id="reconstructed-icons-vae-2">
<a class="reference internal image-reference" href="../../_images/reconstructed_icons_vae_2.png"><img alt="Reconstructed icons using a VAE - watercolor" src="../../_images/reconstructed_icons_vae_2.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 7 </span><span class="caption-text">Undesirable watercolor effect (VAE-reconstructed icons; VAE was trained on 128x128 pixel rasterised vector graphics)</span><a class="headerlink" href="#reconstructed-icons-vae-2" title="Permalink to this image">¶</a></p>
</div>
<p>The figure below shows a “location pin” generated by DALL-E trained on a custom dataset of raster images (after 7 epochs). There were approximately 8,000 examples in this “location pin” class. Practically all examples were symmetrical (could be mirrored along the y axis) and used a perfect circle as shape in the centre. The generated example has lost these properties. For icons, this type of fidelity or precision in the reproduction of concepts matters.</p>
<div class="figure align-default" id="location-pin-generated-by-dall-e">
<a class="reference internal image-reference" href="../../_images/location_pin_generated_by_dall-e.png"><img alt="location_pin_generated_by_dall-e" src="../../_images/location_pin_generated_by_dall-e.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 8 </span><span class="caption-text">Icon of a “location pin” generated by DALL-E trained on a custom dataset of raster images (after 7 epochs)</span><a class="headerlink" href="#location-pin-generated-by-dall-e" title="Permalink to this image">¶</a></p>
</div>
<p>DALL-E is only implicitly learning the symmetry in the training examples; there is no explicit conditioning on these properties.</p>
</div>
<div class="section" id="current-vectorizers-are-doing-a-poor-job">
<h3>2.3 Current vectorizers are doing a poor job<a class="headerlink" href="#current-vectorizers-are-doing-a-poor-job" title="Permalink to this headline">¶</a></h3>
<p>Current tools for converting a raster image (e.g. a PNG) to a vector graphic (“tracing” or “vectorization”) are still doing a poor job.</p>
<p><strong>Main issues with current vectorizers:</strong></p>
<ul class="simple">
<li><p>No context-aware tracing</p>
<ul>
<li><p>E.g. not prior classification of objects and if they should be round or edgy</p></li>
<li><p>E.g. the bottom of a heart shape becomes round (–&gt; incorrect points / edges)</p></li>
<li><p>Identical elements of different sizes may get traced differently.</p></li>
</ul>
</li>
<li><p>No resolution-aware tracing</p>
<ul>
<li><p>At low input resolution, tracers may start to follow pixel borders like steps</p></li>
<li><p>E.g. a vectorizer may fail to recognize that a shape was likely a circle even though it is now a 20x20 pixel blob with step-like sides</p></li>
</ul>
</li>
<li><p>No shape-aware tracing</p>
<ul>
<li><p>Images get vectorized as paths – even though some aspects could be vectorized as basic shapes, e.g circles, rectangles, ellipses</p></li>
</ul>
</li>
<li><p>Potentially incorrect trade-off between accuracy and number of points</p>
<ul>
<li><p>Vectorizers rarely produce elegant results with minimal number of points</p></li>
</ul>
</li>
<li><p>Over-use of points vs. a smart use of bezier curves and their handles</p></li>
<li><p>No or poor detection of colour gradients</p></li>
<li><p>No consideration of symmetry</p>
<ul>
<li><p>Many glyphs and icons have symmetries of some kind (reflectional, translational, rotational, …)</p></li>
<li><p>Current vectorizers are insensitive to symmetries</p></li>
</ul>
</li>
<li><p>Tracers do not understand how humans compose images from multiple shapes (potentially overlapping, potentially half-transparent), e.g. shadows</p></li>
<li><p>SVGs just have too many parameters and an intractable complexity for current vectorizers to correctly guess them all given a raster image</p></li>
</ul>
<p>Even the Deep Learning-based vectorizers Im2Vec cannot fully address the above issues. Im2Vec has been trained on raster images only and lacks awareness of the true underlying composition of the original vector graphics.</p>
</div>
<div class="section" id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h3>
<p><strong>Example 1:</strong></p>
<p>The image below shows the “Octocat”, Github’s mascot.</p>
<div class="figure align-default" id="github-mark">
<a class="reference internal image-reference" href="../../_images/GitHub-Mark.png"><img alt="github" src="../../_images/GitHub-Mark.png" style="width: 300px;" /></a>
<p class="caption"><span class="caption-number">Fig. 9 </span><span class="caption-text">Github’s mascot Octocat</span><a class="headerlink" href="#github-mark" title="Permalink to this image">¶</a></p>
</div>
<p>Note the ellipses on the octocat’s tentacle-tail in the figure above.
Vectorizing a low resolution version of that section of the image leads to a poor result, see the figure below:</p>
<div class="figure align-default" id="vectorizing-still-poor">
<a class="reference internal image-reference" href="../../_images/vectorizing_still_poor.png"><img alt="vectorizing_still_poor" src="../../_images/vectorizing_still_poor.png" style="width: 900px;" /></a>
<p class="caption"><span class="caption-number">Fig. 10 </span><span class="caption-text">Current vectorizers are still performing poorly. In this case, the used tool was <a class="reference external" href="https://vectormagic.com/">vectormagic</a> – still one of the better tools out there and not free.</span><a class="headerlink" href="#vectorizing-still-poor" title="Permalink to this image">¶</a></p>
</div>
<p>The low resolution results in the smaller ellipses to have corners in the vector output. It appears that the vectorizer has no understanding that the resolution of the input is low and pixel edges and corners should not be traced too closely. The vectorizer also has no contextual understanding that there is a symmetry in these shapes: all of these are ellipses of different sizes.</p>
<p><strong>Example 2:</strong></p>
<p>In another example, see figure below, an image loses its perfect symmetry through vectorization.</p>
<div class="figure align-default" id="vectorizing-destroy-symmetry">
<a class="reference internal image-reference" href="../../_images/vectorizing_destroy_symmetry.png"><img alt="vectorizing_destroy_symmetry" src="../../_images/vectorizing_destroy_symmetry.png" style="width: 400px;" /></a>
<p class="caption"><span class="caption-number">Fig. 11 </span><span class="caption-text">Example from <a class="reference external" href="https://github.com/jankovicsandras/imagetracerjs">imagetracerjs</a></span><a class="headerlink" href="#vectorizing-destroy-symmetry" title="Permalink to this image">¶</a></p>
</div>
<p><strong>Example 3:</strong></p>
<p>Vector graphis, such as SVG, can make use of linear and radial gradients. This can produce visually pleasing results, such as this logo below:</p>
<div class="figure align-default" id="edge">
<a class="reference internal image-reference" href="../../_images/edge.svg"><img alt="edge" src="../../_images/edge.svg" width="300px" /></a>
<p class="caption"><span class="caption-number">Fig. 12 </span><span class="caption-text">Microsoft Edge logo designed as a vector graphic in SVG format; <a class="reference external" href="https://www.npmjs.com/package/&#64;browser-logos/edge">source</a></span><a class="headerlink" href="#edge" title="Permalink to this image">¶</a></p>
</div>
<p>Since this logo was designed as an SVG, we know it is possible to design such a logo as a vector graphic.
Here is the SVG code for the logo above:</p>
<div class="figure align-default" id="edge-logo-svg">
<a class="reference internal image-reference" href="../../_images/edge_logo_svg.png"><img alt="edge_logo_svg" src="../../_images/edge_logo_svg.png" style="width: 900px;" /></a>
<p class="caption"><span class="caption-number">Fig. 13 </span><span class="caption-text">SVG code of the Microsoft Edge logo</span><a class="headerlink" href="#edge-logo-svg" title="Permalink to this image">¶</a></p>
</div>
<p>However, current vectorizers have a hard time converting a rasterized version of the logo back to a vector graphic.
These algorithms have no understanding of what (potentially overlapping) shapes are required and what shapes need to have what type of linear or radial gradients. There are too many parameters at play for pre-Deep Learning algorithms to work well.</p>
<div class="figure align-default" id="vectorized-edge-logo">
<a class="reference internal image-reference" href="../../_images/vectorized_edge_logo.png"><img alt="vectorized_edge_logo" src="../../_images/vectorized_edge_logo.png" style="width: 300px;" /></a>
<p class="caption"><span class="caption-number">Fig. 14 </span><span class="caption-text">Screenshot of the vectorized Microsoft Edge logo; vectorized using <a class="reference external" href="https://www.vectorizer.io">vectorizer.io</a>. The vector result is much more complicated than the original SVG and no where near the original in terms of quality.</span><a class="headerlink" href="#vectorized-edge-logo" title="Permalink to this image">¶</a></p>
</div>
<p><strong>Example 4:</strong></p>
<p>Consider the reconstructed icon below:</p>
<div class="figure align-default" id="vectorizers-have-hard-time">
<a class="reference internal image-reference" href="../../_images/vectorizers_have_hard_time.png"><img alt="vectorizers_have_hard_time" src="../../_images/vectorizers_have_hard_time.png" style="width: 300px;" /></a>
<p class="caption"><span class="caption-number">Fig. 15 </span><span class="caption-text">Lacking contextual awareness of current vectorizers</span><a class="headerlink" href="#vectorizers-have-hard-time" title="Permalink to this image">¶</a></p>
</div>
<p>Current vectorizers will not understand that the icon consists of two identical hearts. The black outline on top, and the orange heart underneath and slightly offset.</p>
</div>
<div class="section" id="conclusion-regarding-poor-vectorizers">
<h3>Conclusion regarding poor vectorizers<a class="headerlink" href="#conclusion-regarding-poor-vectorizers" title="Permalink to this headline">¶</a></h3>
<p>Because current vectorizers are performing poorly (and will hopefully soon be replaced by smarter Deep Learning-based algorithms), there is a need to output vector graphics directly. Instead of attempting to output raster images and only then vectorize them.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./02_background/DL_with_vector_graphics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="../DL_with_vector_graphics.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Deep Learning with Vector Graphics</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="challenges_of_vector_graphics.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Challenges of Vector Graphics</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Pascal Wichmann<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>